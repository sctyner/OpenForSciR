---
no-cite: |
  @R-bmp, @R-kableExtra
---

# Latent Fingerprints {#fingerprints}

#### *Karen Kafadar, Karen Pan* {-}

<!--
__Abstract:__

A new measurement to quantify the quality of individual features ("minutiae") in a latent fingerprint is developed. Currently latent fingerprint quality is based on an overall score for an entire print. However, minutiae of sufficiently high quality can be useful for identification even in prints having large sections of low fidelity. We develop a metric with a scale of 0-100 (low to high quality) that characterizes (via gradients) the clarity of ridge features, and calculate the quality metrics on minutiae from NIST's SD27A latent fingerprint database containing prints judged by experts as "good," "bad," or "ugly." The proposed minutiae quality metrics correlate well with the general classification from fingerprint examiners and serve as objective, versus subjective, measures of minutiae quality. The objective quality measure enables examiners to focus on only the highest-scoring minutiae for fingerprint analyses and to discard low-scoring minutiae, thereby removing some aspects of the subjectivity involved in selecting minutiae for comparisons. We then design a procedure to determine a threshold of minutiae quality to distinguish between useful and non-useful minutiae in a forensic identification. We simulate a range of different quality prints by degrading prints of good quality images in a systematic and defined way to find the threshold below which a slated percentage of experts are unable to reliably identify fingerprint features.
-->



## Introduction

Latent fingerprints collected at crime scenes have been widely used for individual identification purposes, primarily because fingerprints have long been assumed to be unique to an individual. Thus it is assumed that some subset of features, or *minutiae*, on a print can be identified and will suffice to determine whether a latent print and a digital print from a database of prints collected under controlled conditions (e.g., in a police laboratory) came from the "same source." However, unlike digital fingerprints in a database, latent prints are generally of poor quality and incomplete, missing ridge structures or patterns. The quality of a latent print, needed for the "Analysis" and "Comparison" phases of the "ACE-V" fingerprint identification process [@swgfast] to assess clarity of the print and specific features of it for identification purposes, is currently judged visually and subjectively, rather than quantitatively, by forensic examiners. Once the examiner identifies seemingly usable minutiae on a latent print, the print is entered into an Automated Fingerprint Identification System (AFIS) which uses the examiner's minutiae to return likely matches from a fingerprint database. Thus, the accuracy of the identification depends first and foremost on the quality and usability of the minutiae in a latent. More independent, high-quality features should lead to more accurate calls (i.e., same or different sources, or "match" or "non-match").

To date, neither an objective measure of quality in selected minutiae, nor the dependence among the features or the number needed for high-accuracy calls, has been considered. Quoting from Ulery et al. (2011) [@ulery_2011], "No such absolute criteria exist for judging whether the evidence is sufficient to reach a conclusion as opposed to making an inconclusive or no-value decision. The best information we have to evaluate the appropriateness of reaching a conclusion is the collective judgments of the experts." A digital fingerprint acquisition system does provide a numerical "quality" score of an exemplar print at the time it is taken (to ensure adequate clarity for later comparison), but the "quality" of the latent fingerprint is typically assessed qualitatively by the examiner.

Some authors have proposed measures of overall latent print quality. Bond (2008) [@bond_2008] defines a five-point scale primarily in terms of ridge continuity. Tabassi et al. (2004) [@tabassi_2004] define a five-point quality scale in terms of contrast and clarity of features tuned to a matcher's performance (high [low] quality associated with good [poor] match performance). Yoon et al. (2012) [@yoon_2012] define a latent fingerprint image quality (LFIQ) score from a user-defined set of features based on clarity of ridges and features. Tabassi et al. (2004, Section 2) [@tabassi_2004] cite other latent print quality measures that have been proposed and conclude that, for all of them, "evaluating their quality measure is a subjective matter" (p.6). Nonetheless, there remains "substantial variability in the attributes of latent prints, in the capabilities of latent print examiners, in the types of casework received by agencies, and the procedures used among agencies" (Ulery et al. 2012) [@ulery_2012]. Consequently, some procedure that offers an objective measure of minutiae quality is needed.

Different features (minutiae) on a latent print supply different amounts of information to an examiner. Thus our goal is to develop a quality metric for each feature, based on a measure of information content in the feature. Visually, a feature on a print (ridge ending, bifurcation, etc.) is more recognizable when it is easily differentiated from the background around it. In the following sections we develop a quality metric for each latent fingerprint feature that quantifies its distinctiveness from its background value, and hence, how reliable a feature might be for purposes of comparison (step 2 of the ACE-V process).

### Contrast Gradient Quality Measurement

The algorithm identifies and examines a small collection of pixels surrounding a given feature and assesses their distinctiveness from the background pixels. The underlying principle for this approach lies in recognizing that a forensic examiner can distinguish features in a fairly blurry latent print by recognizing (1) a gradient of intensity between the dark and light regions defining a minutia point, and (2) an overall contrast of intensity values in the general neighborhood of a minutiae point. The first step is to locate the pixel within a small neighborhood around the minutia location that produces the highest intensity gradient value, and focus calculation around that pixel. The largest gradient in a neighborhood of 5 pixels in each direction from a feature is found. For each pixel in this neighborhood, we compare the pixel intensity, $i(x, y)$, to a neighboring pixel intensity, $i(x + n, y + m)$, where $n$ and $m$ range from -2 to 2, and then divide by the corresponding distance between the pixels to get a measure of the gradient at pixel location $(x, y)$, $g(x, y; n, m)$:

$$ g(x, y; n, m) = \frac{i(x, y) - i(x + n, y + m)}{ \sqrt{n^2 + m^2}}, \qquad n, m = -2, ..., 2. $$

Define $G_5(x, y)$ as the set of all 24 gradients in the $5 \times 5$ neighborhood of $(x, y)$. The value used for the quality measurement is the maximum value in the set $G_5(x, y)$. We define $(x_0, y_0)$ as the point that produces the largest gradient. Next, we find the largest contrast between the point $(x_0, y_0)$ and its immediate $3 \times 3$ neighborhood, $(x_0 + n, y_0 + m)$, or $n_3(x_0, y_0)$, where $n$ and $m$ range from –1 to 1. The contrast factor is the largest intensity difference between $i(x_0, y_0)$ and any neighbor intensity in $n_3(x_0, y_0)$, divided by the maximum intensity in the print, $I_M$, usually 255:

$$ contrast = \frac{max\{abs(i(x_0, y_0) - i(x,y)\}}{I_M}, \qquad (x, y) \in n_3(x_0, y_0). $$

The contrast measurement differs from the gradient measurement because it highlights the maximum change in intensity among all nine points surrounding the minutia point at $(x_0, y_0)$, while the gradient reflects a change in intensity near the minutia point, divided by the distance over that intensity change. Despite the simplicity of this measurement, it quantifies well the visual selection made by a forensic examiner.

### Contrast Gradient Quality Measurement Illustration

To illustrate this measurement, we first look at the gradient values on a clear print with well defined minutiae. Figure \@ref(fig:clearprint) shows such a print. Along with it are close-up views of three minutiae from the print, where the ridge ending and bifurcations are clearly seen. One would expect these very clear minutiae to be at the high end of the quality scale when measuring latent minutiae quality. They are at pixel locations (97, 100), (126, 167), and (111, 68), from the upper left corner. The largest gradients at these 3 locations are 94.0, 66.5, and 88.0 intensity units per grid unit. Looking at gradient values in each $5 \times 5$ neighborhood, we find slightly higher gradient values for each minutia: 107.0, 122.0, and 121.0. For each minutia, we shift our focus point to the new $(x_0, y_0)$ corresponding to the slightly higher gradient value. For these $n_3(x_0, y_0)$ neighborhoods, we find the largest intensity differences to get the contrast. Contrast measures for the three locations are, respectively, 0.447, 0.651, and 0.561, yielding quality metrics 107.0 $\times$ 0.447 = 47.84, 122.0 $\times$ 0.651 = 79.42, and 121.0 $\times$ 0.561 = 67.85. The quality metric ranges from 0.133-100.0 (see Table 1) for NIST's SD27A latent fingerprint database, which has 15008 defined minutia locations. A quality metric value cannot exceed 100.0, and any larger scores are capped at 100.0 (out of the 15008 minutia, only 54 produced quality metrics over 100.0). We now turn to the issue of applying this quality metric to determine the usability of minutiae information in a latent print.

```{r clearprint, out.width = "450px", echo = FALSE, fig.align = 'center', fig.cap = "Figure 1 from [@pk_unpub]. Example of a clear fingerprint and close-up views of three minutiae from this print. Each horizontal green line in the whole print ends at one of the minutia."}
knitr::include_graphics("img/pk_fig1.png")
```

The high quality minutiae above are contrasted with those in a latent print. Previously available database NIST SD27A included latent prints classified as "good," "bad," and "ugly" by forensic examiners to which we apply our quality metric. Figure \@ref(fig:gbugly1) shows three typical latent fingerprints from this data set, one from each class. Figure \@ref(fig:gbugly2) shows a closer look at one of the highest quality minutiae on each of these three latent fingerprints.

```{r gbugly1, out.width = "450px", echo = FALSE,  fig.align="center", fig.cap = "Figure 2 from [@pk_unpub]. Examples of a good, bad, and ugly latent print from the SD27A set: G043, B132, and U296."}
knitr::include_graphics("img/pk_fig2.png")
```

```{r gbugly2, out.width = "450px", echo = FALSE, fig.align="center", fig.cap = "Figure 3 from [@pk_unpub]. Examples of good, bad, and ugly minutiae of approximately the same quality. G043: (502, 741), quality = 21.9, B132: (553, 651), quality = 27.3, and U296: (548, 655), quality = 24.3. Each minutia is located at the center of the 40 × 40 cropped image."}
knitr::include_graphics("img/pk_fig3.png")
```

To understand how our quality measure compares with an examiner's assessment, we select one of the latent prints and show minutiae that were selected by one examiner at different quality levels. Figure \@ref(fig:badlatents) shows a "bad" latent and close-up views of three minutiae with quality scores 5.0, 15.2, and 28.8. The gradient and contrast measures increase from left to right in these $20 \times 20$ pixel images, and the quality metric is calculated within the central one-fourth ($5 \times 5$) of the image.

```{r badlatents, out.width = "450px", echo = FALSE, fig.align = "center", fig.cap = "Figure 4 from [@pk_unpub]. One of the fingerprints labeled as bad, B110, and an expanded view of three of the minutiae from one examiner, in order of quality: (742, 903), quality = 5.0; (727, 741), quality = 15.2; and (890, 405), quality = 28.8. For each minutiae point, the examiner-marked location is at the center of a 20 × 20 square of pixels."}
knitr::include_graphics("img/pk_fig4.png")
```

The SD27A set of latent prints is associated with 849 sets of forensic examiner data, each an ANSI/NIST formatted record, containing the locations of all marked minutiae. From these, we can compare our algorithm's quality metric with the examiner's assessment of "good," "bad," or "ugly." In Table 1, we tabulate the number of minutiae that a forensic examiner located in each set, and the average quality metric of all minutiae in each set. In addition to calculating the average quality metric across all minutiae on the print, we also calculate the average for only those subsets of minutiae with quality metric exceeding 10.0, 20.0, and 30.0. In each set of results, latent prints labeled "good" have more higher-scoring minutiae than prints labeled "bad," and substantially more than prints labeled "ugly." The average minutiae quality metric for each set is similar, suggesting that the assigned label of "good," "bad," or "ugly" is highly influenced by the number of distinguishable (high-scoring) minutiae on the print.

```{r gbutable, results='asis', message = FALSE, echo=FALSE, warning = FALSE}
gbudata <- readr::read_csv("dat/minutiae-table.csv")
gbudata <- gbudata %>% select(-X6, -X7)
names(gbudata)[1] <- "Measurement"
gbudata %>% group_by(type) %>% 
  gt::gt() %>% 
  gt::tab_header("Table 1 from [@pk_unpub]: Numbers of minutiae and average minutiae quality metric (Q) for three sets of minutiae for all sets combined and subsets defined by Q.") %>% 
  gt::tab_footnote("SD = standard deviation", locations = gt::cells_data(
      columns = vars(Measurement),
      rows = Measurement == "(SD)"))
```

<!--
\begin{table}
	\begin{tabular}{lrrr}
		& good & bad & ugly \\
		\hline
		\multicolumn{4}{c}{All minutiae} \\
		Number of sets & 273 & 276 & 300 \\
		Number of minutiae & 7651 & 4313 & 3044 \\
		avg \#minutiae per set & 28.0 & 15.6 & 10.1 \\
		(range min, max) & (0.13,100.0) & (0.18,100.0) & (0.64-100.0) \\
		avg $Q$ per set & 24.4 & 25.4 & 24.2 \\
		(SD) & 17.1 & 18.0 & 18.4 \\
		\multicolumn{4}{c}{Minutiae with $Q > 10.0$} \\
		Number of minutiae & 6213 & 3542 & 2414 \\
		avg \#minutiae per set & 22.8 & 12.8 & 8.0 \\
		(SD) & 12.7 & 6.2 & 3.5 \\
		avg $Q$ per set & 28.5 & 29.6 & 28.9 \\
		(SD) & 16.4 & 17.1 & 17.9 \\
		\multicolumn{4}{c}{Minutiae with $Q > 20.0$} \\
		Number of minutiae & 3873 & 2331 & 1474 \\
		avg \#minutiae per set & 14.2 & 8.4 & 4.9 \\
		(SD) & 11.0 & 5.5 & 3.6 \\
		avg $Q$ per set & 36.7 & 37.3 & 37.9 \\
		(SD) & 15.7 & 16.4 & 17.5 \\
		\multicolumn{4}{c}{Minutiae with $Q > 30.0$} \\
		Number of minutiae & 2160 & 1397 & 854 \\
		avg \#minutiae & 7.9 & 5.0 & 2.8 \\
		(SD) & 8.8 & 4.4 & 3.0 \\
		avg $Q$ per set & 46.4 & 45.8 & 47.8 \\
		(SD) & 15.1 & 16.3 & 17.2 \\
	\end{tabular}
\caption{Numbers of minutiae and average minutiae quality metric ($Q$) for three sets of minutia: All sets combined and subsets defined by $Q$ (SD = standard deviation).}
\end{table}

```{r, out.width = "350px", echo = FALSE, fig.cap = "**Table 1.** Numbers of minutiae and average minutiae quality metric ($Q$) for three sets of minutia for: all sets combined, and subsets defined by $Q$ (SD = standard deviation)."}
knitr::include_graphics("img/pk_tab1.png")
```
--> 

We then compared our minutiae quality metric to the ridge quality map, which is provided in record 9.308 of the American National Standard for Information Systems data format for the Interchange of Fingerprint, Facial, and other Biometric Information [@nist_itl]. The 9.308 record contains a small grid of scores for individual pixels on small sections of the latent print, ranked for the quality of a ridge present in that section, with 5 representing the highest score and 0 the lowest. From these grids of 0-5 values, we obtained the ridge quality scores for individual minutia locations. We compare our (objective) quality metric scores with observer (subjective) ridge qualities for all 15008 minutia in the database. Of the 15008 minutiae, 76 scored 1, 10829 scored 2, 3940 scored 3, 144 scored 4, and 17 scored 5. The corresponding mean quality metric values for scores 1-5 are: 18.6 (measured on the 76 with scores of 1), 23.7, 26.5, 43.2, and 39.9. Corresponding standard deviation values are: 19.9, 17.1, 18.2, 26.1, and 14.8. The means and standard deviations are illustrated with boxplots in Figure \@ref(fig:minqual).

```{r minqual, out.width = "450px", echo = FALSE, fig.align = "center", fig.cap = "Figure 5 from [@pk_unpub]. Minutiae quality vs. ridge quality for all images from the SD27A set, which include 15008 minutiae. Each box height represents the standard deviation of measurements at that ridge quality."}
knitr::include_graphics("img/pk_fig5.png")
```

### Test for Usable Quality

We designed a procedure to identify a threshold for this quality metric, below which the feature is unreliable, and above which it may provide reliable information for comparison purposes. Clear fingerprint images are systematically degraded and quality metric scores calculated for the minutiae accompanying each degraded image. We start by recognizing that a typical clear print has background intensity values of 255 on a scale of 0-255. Accordingly, we simulate different levels of image quality, decreasing the quality of clear prints by lowering the background intensity levels to levels lower than 255. As the background quality is lowered, the contrast between minutiae and background decreases. In this way, we create a series of images from each clear print with different levels of minutiae quality. We can then ask experts to evaluate, in a statistically designed experiment, which minutiae are, in their judgments, sufficiently distinguishable to be useful in a fingerprint analysis, and then note their conclusions following an actual comparison ("correct match found" or "incorrect match found"). This way, a range of $Q$ for minutiae that are highly correlated with accuracy of analysis can be estimated. Clearly, one cannot use actual latent prints for such a study, because (a) the background on latent prints is not well characterized; and (b) "ground truth" is unknown.

Figure \@ref(fig:fptrans) shows an example of a clear print with background starting at 255 followed by a series of prints in which the background is progressively lowered to 100. Figure \@ref(fig:fptranszoom) magnifies the region around three of the minutiae for background values equal to 255 and 100 to show the decreased visibility of the minutiae when the gradients and contrast are severely reduced.

```{r fptrans, out.width = "550px", echo = FALSE, fig.cap = "Figure 6 from [@pk_unpub]. A clear fingerprint on the left and a series of transformations with background intensity lowered from 255 to 220, 200, 180, 160, 140, 120, and 100."}
knitr::include_graphics("img/pk_fig6.png")
```

```{r fptranszoom, out.width = "400px", echo = FALSE, fig.cap = "Figure 7 from [@pk_unpub]. Three of the minutiae from Figure \\@ref(fig:fptrans) with background = 255 (top row) and background = 100 (bottom row)."}
knitr::include_graphics("img/pk_fig7.png")
```

Given a quality metric and a method for systematically decreasing the quality of a fingerprint, we can now design an experiment with different examiners (in terms of experience, type of training, etc.) and correlate the results of their analyses with true outcomes. If accuracy exceeds, say, 95% only when the print has at least $n_0$ minutiae having quality metrics above a threshold $Q_0$, then the examiner has an objective criterion for the "A" (analysis) phase of the ACE-V process.





## Data

```{r, out.width = "350px", echo = FALSE, fig.align='center', fig.cap = "Magnetic fingerprint powder clinging to a rod. Image taken from http://www.stapletonandassociates.com/images/MagPowder.jpg."}
knitr::include_graphics("img/fingerprint_brush.jpg")
```

A common method for recovering unseen latent prints is dusting. Moisture clinging powder is gently brushed onto a surface using soft brushes to detect and increase the visibility of fingerprints. Magnetic powders that cling to a metal rod instead of brush exist that may help minimize possible damage to a print that may occur during dusting. After dusting, prints are usually recorded by lifting -- placing a piece of transparent tape over the fingerprint then transferring the tape, along with the powder, onto a card of contrasting color. Photographs may also be taken of the powdered print. In place of dusting, prints may be chemically processed (super glue, ninhydrin, Rhodamine 6G (R6G), etc.). Clearly visible prints (patent prints) such as those made by paint or blood may be photographed directly. If the fingerprint is left on an object that is easily transported, the object should sent to the forensics lab and photographed to create a digital image.

```{r, out.width = "550px", echo = FALSE, fig.align="center", fig.cap = "Examples of powdered and lifted fingerprints using powders of different color. Image taken from https://www.kinseimatec.co.jp/en/?page_id=1868."}
knitr::include_graphics("img/fingerprint_powders.png")
```

Photographs and fingerprint cards are scanned or otherwise converted to digital format. Enhancements to contrast or color may be made using a photo editing software before producing a finalized grayscale image that may be entered into an AFIS database, directly compared to a suspects' exemplar prints (known fingerprints, e.g., those taken on a tenprint card at a police station), or run through a quality metric algorithm.

The information contained in a fingerprint can be divided into three levels [@doj_fingerprint_sourcebook].

Level 1 detail is the most general, consisting of overall pattern type, friction ridge flow, and morphological information. While insufficient for individualization, level 1 detail may be used for exclusion. "Fingerprint pattern classification" refers to overall fingerprint patterns (e.g., loop, whorl) and their subcategories (e.g., left/right slanted) [@hicklin_2011].

```{r, out.width = "400px", echo = FALSE, fig.align='center', fig.cap = "Level 1 detail in a fingerprint includes overall pattern type and ridge flow, such as loops, whorls, and arches. Image from https://mrthomascooper.weebly.com/."}
knitr::include_graphics("img/level1_detail.jpg")
```

Level 2 detail consists of minutiae and individual friction ridge paths. Minutiae are also called "Galton details" after Sir Francis Galton, the first to define and name specific minutiae (bifurcation, enclosure, ridge endings, island) [@galton_fingerprints].

```{r, out.width = "275px", echo = FALSE, fig.align='center', fig.cap = "Different types of Level 2 detail, or minutiae, in a fingerprint. Image from http://syhrl.blogspot.com/2012/04/036-fyp-minutiae.html."}
knitr::include_graphics("img/minutiae.png")
```

Level 3 detail is the most specific, including friction ridge dimensional attributes such as width, edge shapes, and pores. These details may or may not appear on an exemplar print and are the least reliable.

```{r, out.width = "350px", echo = FALSE, fig.align='center', fig.cap = "Level 3 detail of a fingerprint. Image from http://onin.com/fp/level123.html."}
knitr::include_graphics("img/level3_detail.jpg")
```

### ACE-V and AFIS

Latent prints may be submitted to an AFIS database which will return the top *n* potential matches. Examiners can then perform the ACE-V comparison process on these prints until a "match" is found.

* Analysis: a digitized latent print is analyzed to determine if it is "suitable" for examination. During this process, LPEs mark clear, high quality sections of a print in green, moderate quality sections in yellow, and unclear or distorted sections in red. These colors correspond to features that can be used in comparison, may possibly be used, and will likely not be useful for comparison, respectfully. As level 3 detail is unreliable, LPEs use level 1 and 2 detail to determine if a print is suitable to continue to the comparison step. If not, the ACE-V process ends here.
* Comparison: the latent and exemplar prints are compared side by side. In addition to overall pattern and ridge flow, examiners may look for the existence of target groups -- unique clusters of minutiae -- that correspond between a latent and exemplar. Additional features may be marked in orange.
* Evaluation: a decision of *identification* (formerly "individualization"), *exclusion*, or *inconclusive* is made based on OSAC standards. An inconclusive conclusion may be reached if either print does not contain enough information for a decision. Examiners may request consultation with a colleague before reaching a decision, who would perform an independent markup on the latent.
* Verification: a decision may (or may not) be verified by another examiner who performs an independent markup of the latent print. If the second examiner does not know the first examiner's decision, it is considered a blind verification.

IAFIS is the Integrated Automatic Fingerprint Identification System developed and maintained by the US FBI [@fbi_iafis]. Implemented in 1999, it contains criminal history, photographs, and fingerprints for over 70 million individuals with criminal histories and fingerprints of 34 million civilians [@fbi_iafis, @fbi_ngi]. The FBI's Next Generation Identification (NGI) System was announced in 2014 to extend and improve the capabilities of IAFIS. INTERPOL also maintains a database of over 181,000 fingerprint records and almost 11,000 latent prints [@interpol_fingerprints].

NIST maintains a series of Biometric Special Databases and Software [@nist_biometric], including several fingerprint databases. Special Database 302, not yet released, will contain realistic latent prints and their corresponding exemplars collected from the Intelligence Advanced Research Projects Activity (IARPA) Nail to Nail (N2N) Fingerprint Challenge [@fiumara_talk]. Annotations to these latents may be released at a future data. Special Database 27A, which has since been withdrawn, contained 258 latent and rolled mate pairs that two or more LPEs have agreed "match" [@watson_2015]; i.e., print pairs not guaranteed to be ground truth matches. The latent prints in this database were classified into three categories: good, bad, and ugly, which allows for general testing of correspondence between overall fingerprint quality and quality scores.





## R Package

This R Package implements the Contrast Gradient Quality Measurement for quantifying the quality of individual features, or minutiae, in a latent fingerprint. The primary functions include reading in the fingerprint image into the correct format (`convert_image`) then calculating the quality scores (`quality_scores`). If desired, additional information on gradient and contrast can be output by setting `verbose = TRUE` in the `quality_scores` function. If one wishes to only see gradient and contrast values, these can be output by functions `find_maxgrad` and `find_contrast`, respectively.

https://github.com/kdp4be/fingerprint_package

```{r, echo = TRUE, eval = FALSE}
library(bmp)

# this image is the first of two used in the simple latent case study below
temp_image <- read.bmp("simple_latent.bmp")
# minutiae information (one per row without semicolons): X,Y; 72,22; 72,32; 35,80; 90,85; 59,144
temp_min <- read.csv("simple_latent_min.txt", header = TRUE, sep = ",")

image_file <- convert_image(temp_image, "bmp")
min_file <- as.matrix(temp_min)

# quality scores
quality_scores(image_file, min_file)
quality_scores(image_file, min_file, verbose = TRUE)

# if image already in pixel array format, must be transposed before running quality_scores
text_image <- read.csv("simple_latent.txt", header = FALSE, sep = "\t")
quality_scores(t(text_image), min_file)
```





## Drawing Conclusions

Presently, the first step in fingerprint analysis is the analysis phase, in which the examiner assesses a print for usable minutia that are judged to be sufficiently clear and distinctive for comparison with prints in a database. To reduce the subjectivity in this assessment, we propose a "minutia quality metric" for assessing the clarity, and hence usability, of minutia (e.g., ridge endings, bifurcations, islands) in a fingerprint. The metric is scaled between 0 (totally unusable) and 100 (perfectly clear); more high-scoring minutia should lead to greater distinctiveness in the print and hence fewer false positives that can occur when trying to match latent prints to database prints using much lower-quality minutia. We showed in this article that our metric is both computationally efficient and correlates well with image quality: by systematically (via image algorithms) reducing the image quality of a print (and hence of the minutia), the quality metric decreases accordingly. We also show, using NIST SD27A fingerprint images, that the existence of more high-quality minutia correlates well with the experts' three-category assessment of fingerprint images (good, bad, ugly).

In future work, we plan to evaluate the value of this algorithm for real practice, and estimate false positive and false negative rates with and without the quality metric. We report on this work in a forthcoming article.





## Case Study

```{r fingerglass, out.width = "650px", echo = FALSE, fig.cap = "Five simple fingerprints on a clean glass plate."}
knitr::include_graphics("img/fingerprint_card.png")
```

Five simple fingerprints were created on a clean glass plate using a single finger with differing levels of pressure. These levels range from one to five, with one indicating the largest amount of pressure applied. The glass plate was dusted using a black magnetic powder and the revealed prints lifted with tape onto the back of a white fingerprint card. As expected, as pressure decreases, the latents decrease in overall quality (visually, the ridges are less thick and lose some continuity) and amount of friction ridge area captured. The entire fingerprint card was scanned and each print was cropped into its own grayscale image file. These cropped images were converted into their equivalent 2D pixel array values (0 to 255, black to white).

Five features (ridge endings (E) and bifurcations (B)) from the second and third prints were analyzed using the Contrast Gradient Quality Metric. As the metric is interested in contrast and gradients, the darker, blacker ridges in the Figure \@ref(fig:markedtwo) receive overall higher scores than the lighter gray ridges in the Figure \@ref(fig:markedthree) (feature 3 is an exception).

<!--
```{r csfp1, fig.cap="two images", fig.show='hold', echo = FALSE}
knitr::include_graphics(c("img/print_case_study_2.bmp" ,"img/print_case_study_3.bmp"))
```
-->

<style type="text/css">
.twoC {width: 80%}
.clearer {clear: both}
.twoC .table {max-width: 40%; float: right}
.twoC img {max-width: 40%; float: left; margin-top:50px;}
</style>

<div class="twoC">
```{r markedtwo, out.width = "200px", echo = FALSE, fig.cap="Second print"}
knitr::include_graphics("img/print_case_study_2.bmp")
```
```{r echo=FALSE}
library(kableExtra)
pk_scores <- data.frame(1:5, c("E", "B", "E", "E", "B"), c(70.27, 57.76, 54.99, 58.32, 54.78))
colnames(pk_scores) <- c("Feature", "Type", "Score")
kableExtra::kable(pk_scores, align=rep('c', 5)) %>% kable_styling(full_width = F)
```
</div>
<div class="clearer"></div>

<div class="twoC">
```{r markedthree, out.width = "200px", echo = FALSE, fig.cap="Third print"}
knitr::include_graphics("img/print_case_study_3.bmp")
```
```{r echo=FALSE}
library(kableExtra)
pk_scores <- data.frame(1:5, c("E", "B", "E", "E", "B"), c(29.46, 19.99, 79.86, 20.97, 23.79))
colnames(pk_scores) <- c("Feature", "Type", "Score")
kableExtra::kable(pk_scores, align=rep('c', 5)) %>% kable_styling(full_width = F)
```
</div>
<div class="clearer"></div>


<!--**Fig. 8a (top), 8b (bottom).** Five marked minutiae from latent number 2 (top) and 3 (bottom).-->


Although only five features are marked in the latents above, many more would be identified in casework. In cases where large number of minutiae are identified, minutiae quality scores could allow examiners to focus first on those with higher quality, from which presumably the most reliable information may be obtained. The minutiae in the first image above are relatively clear even to an unexperienced observer, and clearly of better contrast than minutiae in the second image, which the quality scores reflect. Using the quality scores, examiners may be able to focus on high scoring features first, or ignore minutiae scoring below a certain threshold.





<!--
## Acknowledgements

We would like to thank Dr. Adele Peskin for vital discussion and conversation leading to the creation and development of the Contrast Gradient Algorithm as well as an unpublished manuscript [@pk_unpub].
-->

<a rel="license" href="http://creativecommons.org/licenses/by-nc-nd/3.0/us/"><img alt="Creative Commons License" style="border-width:0; display: block; margin-left: auto; margin-right: auto;" src="https://i.creativecommons.org/l/by-nc-nd/3.0/us/88x31.png" /></a>
